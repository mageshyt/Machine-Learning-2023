{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow Part 1: Feature Extraction\n",
        "\n",
        "We've built a bunch of convolutional neural networks from scratch and they all seem to be learning, however, there is still plenty of room for improvement.\n",
        "\n",
        "To improve our model(s), we could spend a while trying different configurations, adding more layers, changing the learning rate, adjusting the number of neurons per layer and more.\n",
        "\n",
        "However, doing this is very time consuming.\n",
        "\n",
        "Luckily, there's a technique we can use to save time.\n",
        "\n",
        "It's called **transfer learning**, in other words, taking the patterns (also called weights) another model has learned from another problem and using them for our own problem.\n",
        "\n",
        "There are two main benefits to using transfer learning:\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has **already learned** patterns on similar data to our own. This often results in achieving great results with less custom data.\n",
        "\n",
        "What this means is, instead of hand-crafting our own neural network architectures or building them from scratch, we can utilise models which have worked for others.\n",
        "\n",
        "And instead of training our own models from scratch on our own datasets, we can take the patterns a model has learned from datasets such as [ImageNet](http://www.image-net.org/) (millions of images of different objects) and use them as the foundation of our own. Doing this often leads to getting great results with less data.\n",
        "\n",
        "Over the next few notebooks, we'll see the power of transfer learning in action.\n",
        "\n",
        "## What we're going to cover\n",
        "\n",
        "We're going to go through the follow with TensorFlow:\n",
        "\n",
        "- Introduce transfer learning (a way to beat all of our old self-built models)\n",
        "- Using a smaller dataset to experiment faster (10% of training samples of 10 classes of food)\n",
        "- Build a transfer learning feature extraction model using TensorFlow Hub\n",
        "- Introduce the TensorBoard callback to track model training results\n",
        "- Compare model results using TensorBoard\n"
      ],
      "metadata": {
        "id": "LK3I_O4CU5Y8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-OHrXO_Qsxs",
        "outputId": "5f53b198-488e-42bd-fa87-241866095450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov  3 16:11:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check for GPU\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and becoming one with data"
      ],
      "metadata": {
        "id": "qVJObzWdWPtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data (10% of labels)\n",
        "import zipfile\n",
        "\n",
        "# Download data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NV6hlWtV8it",
        "outputId": "6ae2430b-d507-47d4-dd57-7676436cbb46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-03 16:11:54--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 142.250.101.207, 2607:f8b0:4023:c0d::cf, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   131MB/s    in 1.2s    \n",
            "\n",
            "2023-11-03 16:11:55 (131 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZuovaPuWVgq",
        "outputId": "e182b30c-0477-437a-e83e-59be8082be4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how each of the training directories now has 75 images rather than 750 images. This is key to demonstrating how well transfer learning can perform with less labelled images.\n",
        "\n",
        "The test directories still have the same amount of images. This means we'll be training on less data but evaluating our models on the same amount of test data."
      ],
      "metadata": {
        "id": "lI7CUbK5Woqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data loaders (preparing the data)\n",
        "\n",
        "Now we've downloaded the data, let's use the [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) class along with the `flow_from_directory` method to load in our images."
      ],
      "metadata": {
        "id": "Dh-JxHRzZkUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import seaborn as sns\n",
        "from tensorflow.keras import models, layers"
      ],
      "metadata": {
        "id": "F3TlfCOQZv5D"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# our image size\n",
        "IMG_SHAPE=(224,224)\n",
        "\n",
        "# batch size\n",
        "BATCH_SIZE=32 # ideal batch size\n",
        "\n",
        "input_shape=[224,224,3]\n",
        "\n",
        "# train and test dir setup\n",
        "\n",
        "train_dir='/content/10_food_classes_10_percent/train'\n",
        "test_dir='/content/10_food_classes_10_percent/test'\n",
        "\n",
        "# make data augmentation\n",
        "train_test_datagen=ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "\n",
        "# make the data [train and test]\n",
        "\n",
        "print(\"👨🏻‍🍳 Making our training data\")\n",
        "\n",
        "train_data=train_test_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SHAPE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "print(\"\\n🧪 Making our testing data\")\n",
        "test_data=train_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SHAPE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cpAfT9OWlXq",
        "outputId": "12abe2c0-4ec1-4613-b2c7-516ae7581401"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "👨🏻‍🍳 Making our training data\n",
            "Found 750 images belonging to 10 classes.\n",
            "\n",
            "🧪 Making our testing data\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run whilst our model trains)\n",
        "\n",
        "Before we build a model, there's an important concept we're going to get familiar with because it's going to play a key role in our future model building experiments.\n",
        "\n",
        "And that concept is **callbacks**.\n",
        "\n",
        "[Callbacks](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks) are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks include:\n",
        "* [**Experiment tracking with TensorBoard**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) - log the performance of multiple models and then view and compare these models in a visual way on [TensorBoard](https://www.tensorflow.org/tensorboard) (a dashboard for inspecting neural network parameters). Helpful to compare the results of different models on your data.\n",
        "* [**Model checkpointing**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) - save your model as it trains so you can stop training if needed and come back to continue off where you left. Helpful if training takes a long time and can't be done in one sitting.\n",
        "* [**Early stopping**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) - leave your model training for an arbitrary amount of time and have it stop training automatically when it ceases to improve. Helpful when you've got a large dataset and don't know how long training will take.\n"
      ],
      "metadata": {
        "id": "BjyeIpL-ckPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a method to tensorboard callbacks\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name,experiment_name):\n",
        "  \"\"\"\n",
        "  this function help us to create tensorboard call back.\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "d4a5t0hBbNbi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because you're likely to run multiple experiments, it's a good idea to be able to track them in some way.\n",
        "\n",
        "In our case, our function saves a model's performance logs to a directory named `[dir_name]/[experiment_name]/[current_timestamp]`, where:\n",
        "* `dir_name` is the overall logs directory\n",
        "* `experiment_name` is the particular experiment\n",
        "* `current_timestamp` is the time the experiment started based on Python's [`datetime.datetime().now()`](https://docs.python.org/3/library/datetime.html#datetime.datetime.now)\n",
        "\n",
        "> 🔑 **Note:** Depending on your use case, the above experimenting tracking naming method may work or you might require something more specific. The good news is, the TensorBoard callback makes it easy to track modelling logs as long as you specify where to track them. So you can get as creative as you like with how you name your experiments, just make sure you or your team can understand them.\n",
        "\n"
      ],
      "metadata": {
        "id": "iPDHDngMjB50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "In the past we've used TensorFlow to create our own models layer by layer from scratch.\n",
        "\n",
        "Now we're going to do a similar process, except the majority of our model's layers are going to come from [TensorFlow Hub](https://tfhub.dev/).\n",
        "\n",
        "In fact, we're going to use two models from TensorFlow Hub:\n",
        "1. [ResNetV2](https://arxiv.org/abs/1603.05027) -  a state of the art computer vision model architecture from 2016.\n",
        "2. [EfficientNet](https://arxiv.org/abs/1905.11946) - a state of the art computer vision architecture from 2019.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-J7o8bJEjthy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oHc7AmaM1CLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the follwing models\n",
        "\n",
        "# Resnet 50 V2 feature vector\n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "# EfficientNet0 feature vector\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ],
      "metadata": {
        "id": "ZzUvLpfLhr7_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url:str,num_class:int=10):\n",
        "  \"\"\"\n",
        "    this function takes the model url and help us to build tensorflow keras model\n",
        "\n",
        "    Args:\n",
        "      model_url(str): A Tensorflow model url\n",
        "      num_class(int): number of output layers\n",
        "\n",
        "    Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "\n",
        "  feature_extractor_layer=hub.KerasLayer(\n",
        "      model_url,\n",
        "      trainable=False,\n",
        "      name=\"feature_extractor_layer\",\n",
        "      input_shape=input_shape\n",
        "  )\n",
        "\n",
        "  model=tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      layers.Dense(num_class,activation=\"softmax\",name=\"output_layer\") # output layer of our model\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "gHducvT91LvB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing ResNet tensorFlow Hub feature Extraction model"
      ],
      "metadata": {
        "id": "lsyciwD-8ZGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create resnet model\n",
        "\n",
        "resnet_model=create_model(resnet_url)\n",
        "\n",
        "# compile the model\n",
        "resnet_model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "# fit the model\n",
        "\n",
        "resnet_model.fit(\n",
        "    train_data,\n",
        "    epochs=5,\n",
        "    steps_per_epoch=len(train_data),\n",
        "    validation_data=test_data,\n",
        "    validation_steps=len(test_data),\n",
        "    # Add TensorBoard callback to model (callbacks parameter takes a list)\n",
        "    callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", # save experiment logs here\n",
        "                                            experiment_name=\"resnet50V2\")]) # name of log files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbo-Cepb4poZ",
        "outputId": "f0e8e220-ba22-41ad-ad35-5bc49de4b911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/resnet50V2/20231103-161349\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 24s 527ms/step - loss: 1.8904 - accuracy: 0.3640 - val_loss: 1.2164 - val_accuracy: 0.6144\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 13s 562ms/step - loss: 0.9263 - accuracy: 0.7213 - val_loss: 0.8296 - val_accuracy: 0.7432\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 11s 455ms/step - loss: 0.6339 - accuracy: 0.8213 - val_loss: 0.7497 - val_accuracy: 0.7592\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - ETA: 0s - loss: 0.4862 - accuracy: 0.8720"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsv05l3o9Aqx"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}